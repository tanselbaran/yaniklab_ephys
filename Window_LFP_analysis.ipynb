{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evoked LFP Analysis in Time Windows\n",
    "\n",
    "This script is for breaking down a recording session and analyzing how the characteristics of the stimulus-evoked LFP response change over time windows indicated by the user. Please follow the upcoming steps in this notebook to perform the analysis. <b> You need to enter information and re-run the code for every recording session you want to analyze in time windows. </b>\n",
    "\n",
    "## 1) Import the packages required for the analysis\n",
    "\n",
    "Please run the following block of code to import the Python packages that are required to run the rest of this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import ipywidgets \n",
    "import math\n",
    "from matplotlib.pyplot import *\n",
    "from ipywidgets import VBox, HBox\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Enter the path and the parameters for the analysis\n",
    "\n",
    "Please run the following block of code and enter the relevant information in the IPython widgets that show up after running the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating widgets for the user input on the general parameters for the experiment\n",
    "\n",
    "##Main path for the data \n",
    "\n",
    "mp_html = ipywidgets.HTML(value = \"<p><b>Path to the data:</b><br />Enter the path to the folder (with no '/' at the end) that is hierarchically right above the folders of the recording sessions</p>\")\n",
    "mp = ipywidgets.Text(value = \"\", placeholder = \"Enter path for data\", disabled = False)\n",
    "display(VBox([mp_html, mp]))\n",
    "\n",
    "##Name of the folder to be analyzed \n",
    "\n",
    "fn_html = ipywidgets.HTML(value = \"<p><b>Name of the folder containing the recording session to be analyzed:</b><br />Enter the name of the folder (with no '/' at the end) that contains the recording session which you want to analyze in time windows.</p>\")\n",
    "fn = ipywidgets.Text(value = \"\", placeholder = \"Enter folder name\", disabled = False)\n",
    "display(VBox([fn_html, fn]))\n",
    "\n",
    "##Length of the time window \n",
    "\n",
    "tw_html = ipywidgets.HTML(value = \"<b>Length of the time windows that you want the recording session to be broken into (in minutes)</b>\")\n",
    "tw = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([tw_html, tw]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Analysis \n",
    "\n",
    "Please run the following block of code to perform the analysis based on the input that you provided above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = pickle.load(open(mp.value + '/' + fn.value + '/paramsDict.p', 'rb')) #Loading parameter dictionary\n",
    "len_time_window = tw.value * 60 * p['sample_rate'] #Converting the time window length from minutes to number of samples\n",
    "analyzed_path_for_folder = mp.value + '/analyzed/' + fn.value\n",
    "\n",
    "for probe in range(p['probes']):\n",
    "    for shank in range(p['shanks']):\n",
    "        analyzed_path_for_shank = analyzed_path_for_folder + '/probe_{:g}_shank_{:g}/'.format(probe,shank)\n",
    "        \n",
    "        #Loading the evoked LFP data from the evoked LFP pickle saved by the evoked_LFP_analysis.py script\n",
    "        data_location = mp.value + '/' + fn.value + ('/probe_{:g}_shank_{:g}'.format(probe,shank)) + ('/probe_{:g}_shank_{:g}_evoked.pickle'.format(probe,shank))\n",
    "        evoked_data = pickle.load(open(data_location, 'rb'))\n",
    "        evoked = evoked_data['evoked']\n",
    "        stim_timestamps = evoked_data['stim_timestamps']\n",
    "        \n",
    "        num_window = int(np.max(stim_timestamps) / len_time_window) #Calculating number of time windows in data\n",
    "        windows = np.arange(0,num_window,1)\n",
    "        \n",
    "        evoked_window_avgs = np.zeros((num_window, len(evoked[0]), len(evoked[0][0]))) #Averages of the evoked LFPs over time window\n",
    "        evoked_window_err = np.zeros((num_window, len(evoked[0]), len(evoked[0][0]))) #Standard errors of the evoked LFPs over time window\n",
    "        evoked_window_amps = np.zeros((p['probes'], p['shanks'], p['nr_of_electrodes_per_shank'], num_window)) #Amplitude of the evoked LFPs over time window\n",
    "        evoked_window_peak_errs = np.zeros((p['probes'], p['shanks'], p['nr_of_electrodes_per_shank'], num_window)) #Error of the amplitude of the evoked LFPs over time window\n",
    "        \n",
    "        for window in range(num_window):\n",
    "            print(\"Time: {:g}\".format(window))\n",
    "            evoked_window = evoked[np.all([stim_timestamps > window * len_time_window, stim_timestamps < (window + 1) * len_time_window], axis = 0)] #Finding all the evoked data for which the time stamp falls in the window of interest\n",
    "            evoked_window_avgs[window] = np.mean(evoked_window, 0)\n",
    "            evoked_window_std = np.std(evoked_window, 0) #Standard deviation of the data in the time window\n",
    "            evoked_window_err[window] = evoked_window_std / math.sqrt(len(evoked_window)) #Standard error of the evoked LFP data in the time window\n",
    "       \n",
    "            for trode in range(p['nr_of_electrodes_per_shank']):\n",
    "                evoked_window_amps[probe][shank][trode][window] = np.max(evoked_window_avgs[window][trode]) - np.min(evoked_window_avgs[window][trode]) #Amplitude of the average evoked LFP                 \n",
    "                min_error = evoked_window_err[window][probe][np.where(evoked_window_avgs[window][trode] == np.min(evoked_window_avgs[window][trode]))] #Standard error at the min value\n",
    "                max_error = evoked_window_err[window][probe][np.where(evoked_window_avgs[window][trode] == np.max(evoked_window_avgs[window][trode]))] #Standard error at the max value\n",
    "                if len(min_error) == 1:   \n",
    "                    evoked_window_peak_errs[probe][shank][trode][window] = math.sqrt(min_error ** 2 + max_error ** 2)\n",
    "        \n",
    "        for trode in range(p['nr_of_electrodes_per_shank']):\n",
    "            figure()\n",
    "            plot(windows, evoked_window_amps[probe][shank][trode], 'k-')\n",
    "            xlabel('Time (min)')\n",
    "            ylabel('Peak voltage (uV)')\n",
    "            errorbar(windows, evoked_window_amps[probe][shank][trode], yerr = evoked_window_peak_errs[probe][shank][trode])\n",
    "            savefig(analyzed_path_for_shank + '/electrode' + str(trode) + '_time_windows.svg', format = 'svg')\n",
    "            close()\n",
    "                \n",
    "        #Save the window LFP analysis in a pickle file\n",
    "        save_file = analyzed_path_for_folder + '/probe_{:g}_shank_{:g}/probe_{:g}_shank_{:g}_window_LFP.pickle'.format(probe,shank,probe,shank)\n",
    "        pickle.dump({'evoked_window_avgs':evoked_window_avgs, 'evoked_window_err':evoked_window_err}, open(save_file, 'wb'), protocol = -1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done! \n",
    "\n",
    "Notebook written by Baran Yasar in 04/2017. Please contact him in person or e-mail at yasar@biomed.ee.ethz.ch in case of any questions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
